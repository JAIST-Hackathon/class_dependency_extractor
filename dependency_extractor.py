"""dependency_extractor.py  ğŸš€ 2025â€‘06â€‘14

JAIST æƒ…å ±ç§‘å­¦ç³»ï¼ˆçŸ³å·ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹ï¼‰ã®ã‚·ãƒ©ãƒã‚¹ CSV 2 ã¤ã‚’èª­ã¿è¾¼ã¿ã€
ç§‘ç›®é–“ã®ä¾å­˜ã‚°ãƒ©ãƒ• **source,target,label** ã‚’ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

â— **ãƒ¢ãƒ‡ãƒ«åã¯ CLI ã§å¤‰æ›´å¯èƒ½** (`--model`).
   - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: `gpt-4o`  
   - o3 ã‚’ä½¿ã„ãŸã„å ´åˆã¯ OpenAI çµ„ç¹”ã‚’ Verify ã—ãŸã†ãˆã§ `--model o3` ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚

-----------------------------------------------------------------------
ãƒã‚¤ãƒ©ã‚¤ãƒˆ
-----------------------------------------------------------------------
1. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚’æ­£è¦è¡¨ç¾ã§æ‹¡å¼µ (ã€Œç‰¹è«–ã€ã®æœ‰ç„¡ã‚’è¨±å®¹)
2. è¬›ç¾©ã‚³ãƒ¼ãƒ‰ã‚’æ­£è¦åŒ– (å…¨è§’â†’åŠè§’ãƒ»ç©ºç™½é™¤å»)
3. GPT å‘¼ã³å‡ºã—ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ã (temperature éå¯¾å¿œ / æœªæ¤œè¨¼ãƒ¢ãƒ‡ãƒ«)
4. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ `.gpt_cache.json` ã«ã‚ˆã‚Šå†å®Ÿè¡Œãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›
5. `--debug` ã§è¡Œã”ã¨ã®ãƒ’ãƒƒãƒˆæ•°ã‚’è¡¨ç¤º

-----------------------------------------------------------------------
PowerShell å®Ÿè¡Œä¾‹ (Windows)
-----------------------------------------------------------------------
```powershell
pip install pandas openai python-dotenv regex
setx OPENAI_API_KEY "sk-..."
# ãƒ¢ãƒ‡ãƒ«æŒ‡å®šãªã— â†’ gptâ€‘4o
python dependency_extractor.py --details syllabus_details.csv --master jaist_syllabus_cs_ishikawa_2025.csv
# o3 ã‚’è©¦ã™ (çµ„ç¹” Verify æ¸ˆã¿ã®ã¨ã)
python dependency_extractor.py --model o3 --details syllabus_details.csv --master jaist_syllabus_cs_ishikawa_2025.csv
```
"""

from __future__ import annotations

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import argparse
import hashlib
import json
import os
import re
import sys
from pathlib import Path
from typing import Dict, List

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import pandas as pd
from openai import OpenAI
import regex as re2  # æ­£è¦è¡¨ç¾å¼·åŒ–ç‰ˆ

# ---------------------------------------------------------------------------
# è¨­å®šå€¤
# ---------------------------------------------------------------------------
DEFAULT_MODEL = "gpt-4o"            # o3 ãŒä½¿ãˆãªã„å ´åˆã§ã‚‚å‹•ãå®‰å…¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
CACHE_FILE = Path(".gpt_cache.json")
PATTERN_CODE = re.compile(r"(I\d{3,7})ï¼ˆ([^ï¼‰]+)ï¼‰")
BASE_KEYWORDS = [
    "å¾®åˆ†ç©åˆ†", "ç·šå½¢ä»£æ•°", "ç¢ºç‡çµ±è¨ˆ", "æƒ…å ±ç†è«–",
    "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¨ãƒ‡ãƒ¼ã‚¿æ§‹é€ ", "è«–ç†å›è·¯",
    "ã‚ªãƒšãƒ¬ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ç‰¹è«–", "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£",
]
KEYWORDS_REGEX = [re2.compile(fr"{kw}(?:ç‰¹è«–)?") for kw in BASE_KEYWORDS]

# ---------------------------------------------------------------------------
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ---------------------------------------------------------------------------

def _sha(text: str) -> str:
    return hashlib.sha256(text.encode()).hexdigest()

def _load(path: Path) -> Dict[str, str]:
    return json.loads(path.read_text()) if path.exists() else {}

def _save(obj: Dict[str, str], path: Path):
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2))

# ---------------------------------------------------------------------------
# GPT ãƒ©ãƒ™ãƒ«åˆ¤å®š (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯+æ¸©åº¦è‡ªå‹•èª¿æ•´)
# ---------------------------------------------------------------------------

def classify(client: OpenAI, text: str, item_type: str, cache: Dict[str, str], model: str) -> str:
    """GPT ã§ 6 ãƒ©ãƒ™ãƒ«ã«åˆ†é¡ã€‚ãƒ¢ãƒ‡ãƒ«ä¸å¯/temperature éå¯¾å¿œã‚’è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    key = _sha(f"{item_type}|{text}|{model}")
    if key in cache:
        return cache[key]

    # â€”â€”â˜… ã“ã“ãŒ *æœ€åˆ* ã«æç¤ºã—ãŸ sys_prompt â˜…â€”â€”
    sys_prompt = (
        "ã‚ãªãŸã¯å¤§å­¦ã‚·ãƒ©ãƒã‚¹ã®è¨˜è¿°ã‹ã‚‰ç§‘ç›®é–“ã®ä¾å­˜é–¢ä¿‚ãƒ©ãƒ™ãƒ«ã‚’åˆ¤å®šã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚\n"
        "ä»¥ä¸‹ã® 6 ç¨®é¡ã®ãƒ©ãƒ™ãƒ«ã®ã„ãšã‚Œã‹ã‚’ **å¿…ãš 1 å˜èªã ã‘** å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
        "unrelated : ä»–ã®ç§‘ç›®ã¨ç›´æ¥ã®é–¢é€£ã¯ãªã„\n"
        "recommended : å±¥ä¿®ãŒæœ›ã¾ã—ã„ï¼ˆæº–å‚™å­¦ç¿’ï¼‰\n"
        "equivalent : ç›¸å½“ã™ã‚‹çŸ¥è­˜ãŒå¿…è¦ï¼ˆå‰æçŸ¥è­˜ï¼‰\n"
        "required : å±¥ä¿®ãŒå¿…é ˆï¼ˆå‰ææ¡ä»¶ï¼‰\n"
        "exclusive : å±¥ä¿®ã—ã¦ã„ã‚‹ã¨å—è¬›ä¸å¯ï¼ˆæ’ä»–é–¢ä¿‚ï¼‰\n"
        "related   : ä¸Šè¨˜ã«å½“ã¦ã¯ã¾ã‚‰ãªã„ãŒé–¢é€£ãŒã‚ã‚‹ç§‘ç›®\n\n"
        "ä¸ãˆã‚‰ã‚ŒãŸ 'item_type' (related_items/prerequisites) ã‚‚è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚\n"
        "è¿”ç­”ã¯ãƒ©ãƒ™ãƒ«åã®ã¿ã€‚è§£èª¬ã‚„å¥èª­ç‚¹ã¯ä¸è¦ã§ã™ã€‚"
    )
    usr_prompt = f"item_type: {item_type}\ntext: {text}"

    # ãƒ¢ãƒ‡ãƒ«å€™è£œãƒã‚§ãƒ¼ãƒ³
    chain = [model, "gpt-4o", "gpt-3.5-turbo"]
    last_err: Exception | None = None

    for m in chain:
        for attempt in ("with_temp", "no_temp"):
            try:
                payload = dict(model=m, messages=[
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": usr_prompt},
                ])
                if attempt == "with_temp":
                    payload["temperature"] = 0
                resp = client.chat.completions.create(**payload)
                label = resp.choices[0].message.content.strip()
                cache[key] = label
                return label
            except Exception as e:
                last_err = e
                msg = str(e)
                # temperature unsupported â†’ æ¬¡ã® attempt
                if "unsupported_value" in msg and "temperature" in msg and attempt == "with_temp":
                    continue
                # model not found â†’ æ¬¡ã®ãƒ¢ãƒ‡ãƒ«
                if "model_not_found" in msg or "must be verified" in msg:
                    break
                raise  # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯å³çµ‚äº†
    raise last_err if last_err else RuntimeError("å…¨ãƒ¢ãƒ‡ãƒ«å¤±æ•—")

# ---------------------------------------------------------------------------
# ãƒã‚¹ã‚¿è¾æ›¸ä½œæˆ & æ­£è¦åŒ–
# ---------------------------------------------------------------------------

def _norm(code: str) -> str:
    return re.sub(r"\s+", "", code).upper()


def build_map(df: pd.DataFrame) -> Dict[str, str]:
    mapping = {}
    for _, r in df.iterrows():
        mapping[_norm(str(r["ç§‘ç›®ã‚³ãƒ¼ãƒ‰"]))] = r["è¬›ç¾©åç§°"]
        mapping[_norm(str(r["è¬›ç¾©ã‚³ãƒ¼ãƒ‰"]))] = r["è¬›ç¾©åç§°"]
    return mapping

# ---------------------------------------------------------------------------
# ä¾å­˜ã‚¨ãƒƒã‚¸æŠ½å‡º
# ---------------------------------------------------------------------------

def extract(df: pd.DataFrame, mapping: Dict[str, str], client: OpenAI, model: str, debug: bool) -> pd.DataFrame:
    cache = _load(CACHE_FILE)
    edges: List[Dict[str, str]] = []

    for idx, row in df.iterrows():
        tgt_code = _norm(str(row["ç§‘ç›®ã‚³ãƒ¼ãƒ‰"]))
        tgt_name = mapping.get(tgt_code, tgt_code)
        sentence = str(row["å†…å®¹"])
        relation = classify(client, sentence, row["é …ç›®"], cache, model)

        hit = 0
        # A) explicit Iã‚³ãƒ¼ãƒ‰
        for code, _ in PATTERN_CODE.findall(sentence):
            edges.append({"source": mapping.get(_norm(code), code), "target": tgt_name, "label": relation})
            hit += 1
        # B) keyword
        for rx in KEYWORDS_REGEX:
            if rx.search(sentence):
                edges.append({"source": rx.pattern.split("(?:ç‰¹è«–)?")[0], "target": tgt_name, "label": relation})
                hit += 1
        if debug:
            print(f"row {idx}: hits={hit} label={relation}")

    _save(cache, CACHE_FILE)
    return pd.DataFrame(edges).drop_duplicates().reset_index(drop=True)

# ---------------------------------------------------------------------------
# CLI
# ---------------------------------------------------------------------------

def main():
    ap = argparse.ArgumentParser(description="JAIST ã‚·ãƒ©ãƒã‚¹ CSV â†’ ä¾å­˜ã‚°ãƒ©ãƒ• (source,target,label)")
    ap.add_argument("--details", required=True, help="syllabus_details.csv")
    ap.add_argument("--master", required=True, help="jaist_syllabus_cs_ishikawa_2025.csv")
    ap.add_argument("--out", default="dependency_graph.csv", help="å‡ºåŠ› CSV ãƒ•ã‚¡ã‚¤ãƒ«å")
    ap.add_argument("--model", default=DEFAULT_MODEL, help="ChatGPT model (ä¾‹: gpt-4o / o3)")
    ap.add_argument("--debug", action="store_true", help="è¡Œå˜ä½ã®ãƒ’ãƒƒãƒˆæ•°ã‚’è¡¨ç¤º")
    args = ap.parse_args()

    if not os.getenv("OPENAI_API_KEY"):
        sys.exit("âŒ OPENAI_API_KEY ã‚’ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã—ã¦ãã ã•ã„")

    client = OpenAI()
    details_df = pd.read_csv(args.details)
    master_df = pd.read_csv(args.master)
    mapping = build_map(master_df)
    dep_df = extract(details_df, mapping, client, args.model, args.debug)

    if dep_df.empty:
        sys.exit("âš ï¸  ä¾å­˜é–¢ä¿‚ãŒ 0 ä»¶ã§ã—ãŸã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰/æ­£è¦è¡¨ç¾ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    dep_df.to_csv(args.out, index=False)
    print(f"âœ… å®Œäº†: {args.out} (rows={len(dep_df)})")

if __name__ == "__main__":
    main()
